

# Sun-Shine: The First Large Language Model for Tibetan Culture 

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![arXiv](https://img.shields.io/badge/arXiv-2407.10671-b31b1b.svg)](https://arxiv.org/abs/2407.10671)

**Code & Model Release Coming Soon**  

## ðŸŒŸ Overview

**Sun-Shine** is the first â€‹post-trained large language model specifically designed for Tibetan cultural understanding and processing. Built on the LLaMA-3.1 architecture through a complete post-training paradigm with our novel **TIB-STC** dataset (the first comprehensive Tibetan corpus), it demonstrates state-of-the-art performance in:
- Classical Tibetan text processing
- Low-resource language understanding
- Cultural context preservation
- Cross-lingual translation (Tibetanâ†”Chineseâ†”English)

**Key Features:**
- 8B parameter model with optimized Tibetan linguistic features
- Superior performance to 671B models in Tibetan-specific tasks
- Enhanced safety alignment for cultural sensitivity
- Classical grammar preservation through expert-curated data


## ðŸ“‚ TIB-STC Dataset

The first large-scale Tibetan corpus containing:

- 122M instances | 11B tokens | 18GB data
- 5 sub-datasets covering:
  - Classical literature & religious texts
  - Modern news & conversational data
  - Safety alignment prompts
  - Human preference annotations

## ðŸ“œ Citation

```bibtex
@article{huang2024sunshine,
  title={Sun-Shine: A Large Language Model for Tibetan Culture},
  author={Huang, Cheng and Gao, Fan and Tashi, Nyima and Liu, Yutong et al.},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}
```


